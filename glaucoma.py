# -*- coding: utf-8 -*-
"""glaucoma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/144Py64UeG8j01IWPHh3_tTx61t4UX-IG
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("glaucoma.csv")

df.head()

df.tail()

df.shape

df.columns

df.duplicated().sum()

df.isnull().sum()

df.info()

df.describe()

df.nunique()

df=df.drop(['Patient ID'],axis=1)

object_columns = df.select_dtypes(include=['object','bool']).columns
print("Object type columns:")
print(object_columns)

numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns
print("\nNumerical type columns:")
print(numerical_columns)

def classify_features(df):
    categorical_features = []
    non_categorical_features = []
    discrete_features = []
    continuous_features = []

    for column in df.columns:
        if df[column].dtype in ['object', 'bool']:
            if df[column].nunique() < 30:
                categorical_features.append(column)
            else:
                non_categorical_features.append(column)
        elif df[column].dtype in ['int64', 'float64']:
            if df[column].nunique() < 30:
                discrete_features.append(column)
            else:
                continuous_features.append(column)

    return categorical_features, non_categorical_features, discrete_features, continuous_features

categorical, non_categorical, discrete, continuous = classify_features(df)

print("Categorical Features:", categorical)
print("Non-Categorical Features:", non_categorical)
print("Discrete Features:", discrete)
print("Continuous Features:", continuous)

df=df.drop(['Medication Usage', 'Visual Field Test Results', 'Optical Coherence Tomography (OCT) Results', 'Visual Symptoms'],axis=1)

df = df.drop_duplicates()

df.isnull().sum()

df=df.drop(['Medical History'],axis=1)

df

categorical, non_categorical, discrete, continuous = classify_features(df)

print("Categorical Features:", categorical)
print("Non-Categorical Features:", non_categorical)
print("Discrete Features:", discrete)
print("Continuous Features:", continuous)

object_types = ['Gender', 'Visual Acuity Measurements', 'Family History', 'Cataract Status', 'Angle Closure Status', 'Diagnosis']

df_dummies = pd.get_dummies(df[object_types])

df_dummies

from imblearn.over_sampling import SMOTE

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
df[['Age', 'Intraocular Pressure (IOP)', 'Cup-to-Disc Ratio (CDR)', 'Pachymetry']] = scaler.fit_transform(df[['Age', 'Intraocular Pressure (IOP)', 'Cup-to-Disc Ratio (CDR)', 'Pachymetry']])

df['Glaucoma Type'].value_counts()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from imblearn.over_sampling import RandomOverSampler

X = df.drop('Glaucoma Type', axis=1)
y = df['Glaucoma Type']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Before Oversampling:", y_train.value_counts())

ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(X_train, y_train)

print("After Oversampling:", y_train_res.value_counts())

log_reg = LogisticRegression(max_iter=1000, solver='liblinear')

# One-hot encode categorical columns before fitting the model
categorical_for_encoding = [col for col in categorical if col != 'Glaucoma Type']
X_train_res = pd.get_dummies(X_train_res, columns=categorical_for_encoding)
X_test = pd.get_dummies(X_test, columns=categorical_for_encoding)

log_reg.fit(X_train_res, y_train_res)

y_pred = log_reg.predict(X_test)

print("Classification Report:")
print(classification_report(y_test, y_pred))

print("Accuracy Score:", accuracy_score(y_test, y_pred))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

from sklearn import svm
svc = svm.SVC()
svc.fit(X_train_res, y_train_res)

y_pred = svc.predict(X_test)

report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import pickle
with open('logreg_model.pkl', 'wb') as file:
    pickle.dump(log_reg, file)
print("Model saved as logreg_model.pkl")

